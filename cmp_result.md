### tf-idf 用C++重写
同样是在100行作为训练数据x上 , 
Python写的tf-idf模块耗时1.26740002632s , 
用C++写并用swig转成Python库的模块耗时0.0544438362122s. 

以下是在不同数据量级上C++库的总耗时(s)：
100: 0.0544438362122
1000: 0.508544921875
10000: 5.33215904236
100000: 39.6013920307
500000: 347.026870966

由于根据阈值筛选特征在tf-idf的同时进行，因此如果将阈值设得越高，理论上程序运行得会越快，体现在将符合条件的值插入到输出map上，由于要插入的值更少，因此用于插入的时间会更少。但不会有太大的提升。
比如同样是500000条记录做tf-idf, 如果将阈值设为1， 那么总耗时是 252.492651939

以下是同样500000条记录在不同的阈值下的运行时间(s)：

1: 252.492651939
2: 244.328693151

### 补充
用C++重写并不会永远都有用。最大的缺点在于，有时候需要显示地将Python类型的对象转成C++类型的对象，比如将dict转成某种map结构，这样会带来大量的用于map结构初始化的成本。
当程序遇到性能瓶颈时，关键是要定位到瓶颈的问题，而不是基于猜测的原因进行优化。一定要基于实证。
