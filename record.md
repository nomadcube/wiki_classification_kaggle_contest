### 进度

1. 已完成
- 前期数据处理和降维模块
- 后期模型评估模块
- 用liblinear实现多元logistic回归

2. 存在问题
- 模型训练慢，看起来像是算法不收敛
- tf-idf的阈值设置需要调整

### 数据分析

- 真实分类多

描述性统计结果（耗时44.392799139s）：

```
basic_statistics(min_val=1, max_val=1344, median=20, mean_val=27.61187490936296)
```
共1475666个不同的y，最少的覆盖1个样本，最大的覆盖1344（0.1%）个样本，中位数是20，均值是27.6，呈现左偏，但不是太严重。

- 特征维度高

特征维度近20万。这些特征都是词条，可以设合理的tf-idf阈值来降维。

- 真实分类所包含叶结点的关系
据官方文档，真实分类只包含层次关系的叶结点。某条分类中的若干个叶结点可能属于同一个父结点。这样对于那些特别稀疏的叶结点可以合并成它们的父结点，作为预测目标。即先预测父结点，再对相同父结点的样本预测子结点。


### 程序效率

1. 问题
将2365436行读入内存并分割x, y耗时过长，理论上时间复杂度是 O(m*p) , 其中m是样本数，p是平均每条样本包含的特征数。liblinear的svm_read_problem()方法用的也是类似的读入逻辑，估计用python直接将200万行的文件直接读入内存必然会效率低下的。又或者是因为我的机器内存太低？
在一个完整的数据挖掘流程中，需要优化的不仅是解算法最优化的过程，因为这个过程只占其中很小一部分，很大一部分是在数据的读写和处理，包括特征处理等。
以下是在完整训练数据上抽取前k条来测试数据处理（提取y和x）的耗时：

2. 改进方法
不要一次处理太多问题，将TrainData的各个逻辑解开。
改进后的耗时还可以接受嗯：

- 10000: 1.93s
- 100000: 14s
- 1000000: 160s
- 2365436: 347s

### 模型效果
取数据的前100行作为训练集，第101到200行作为测试集。
在训练集和测试集上分别用tf-idf作降维。
用降维后的x作为分类器的输入数据。
首先尝试的是liblinear的线性分类器，具体参数是'-s 0 -c 1'，即正则化系数为1，模型为带l2正则项的logistic回归，用原问题作为最优化求解的目标函数。
求解结束时的输出是```iter  3 act 7.720e-07 pre 7.720e-07 delta 3.574e+00 f 6.144e+01 |g| 1.420e-03 CG   2```, 即当|w_(t+1) - w_t|为3.574e+00，|f_(t+1) - f_t|为6.144e+01，梯度差为1.420e-03时结束迭代。
分类的效果是非常地过拟合：在训练集上准确率达到100％，即macro precision和macro recall都为1，但在测试集上准确率只有1％，而且macro precision和macro recall分别为0.008和0.017. 

